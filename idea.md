### 关注点

* 现有的关于文档检索结合知识图谱检索的方面对于文档方面的利用不够充分
增大文档语意连贯性的利用，补充KG稀疏性，而不是仅仅只依赖知识图谱的结构化查询
通过一些小模型去处理文档再输入到llm，会让llm更好理解

* 检索关系得到三元组去对实体检索得到三元组做补充



## Query扩写
* 对Query进行扩写以获取更多信息。
* 可设立Adaptive架构，动态评估是否需要扩写

​
## 文档检索
* 通过MRC（机器阅读理解）总结内容，储存topic。
* 查询时依据问题相关性，找到最匹配的Topk文档
* 索引到原文档（输入Query）→ 提取问题相关证据/语义分割 → 总结得到查询结果。


## 图谱查询
* 提取实体后执行多跳查询 
* 仅查询实体可能遗漏信息，需从Query提取关系做相似度查询。返回Topk关系 → 检索关系的具体相关三元组 → 筛选相关三元组
       最后去重，返回三元组。

## 生成答案
将图谱查询结果和文档检索结果输入到llm生成回答

---

## 参照论文EWEK-QA（24ACL）对细节进行补充

* 原论文结合web查询和图谱查询

* 在文档检索中可参考ToG-E的多跳查询（EWEK-QA对TOG做的改进:ToG-E​（ToG-Efficient）用SentenceBERT替换TOG流程中的LLM进行相似度计算

* 在图谱检索中可参考论文架构中的证据提取器（Evidence Extractor, 微调预训练模型（如DeBERTa)学习从网页文本中定位与问题最相关的连续文本跨度（Span），而非简单截取固定长度内容）和段落分割     （Paragraph Splitter，按照语义完整性分割文档内容）

* 检索与重排序原论文使用了两阶段模型：
  过滤模型（Filtration Model）​MiniLM（6层，22M参数）快速过滤无关段落，保留Top-70候选。
​  重排序模型（Re-ranker）​：DeBERTa（900M参数）对过滤后的段落按语义相关性重新排序。


